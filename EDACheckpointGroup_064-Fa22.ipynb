{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Hugs Clorina\n",
    "- John Howell\n",
    "- Andy Chow\n",
    "- Jawad Osman\n",
    "- Vince Ermitano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a statistically significant correlation between rising ocean temperature and sea level with the frequency of unprovoked shark attacks in North America?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn and apply its plotting styles\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2, style=\"white\")\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# set plotting size parameter\n",
    "plt.rcParams['figure.figsize'] = (17, 7)\n",
    "\n",
    "# import pandas & numpy library\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# read in all datasets\n",
    "sharks_df = pd.read_csv(\"./shark_attacks.csv\")\n",
    "temp_df = pd.read_csv(\"./temperature_anomalies.csv\")\n",
    "sl_pacific_df = pd.read_csv(\"./sea_level_north_pacific.csv\")\n",
    "sl_atlantic_df = pd.read_csv(\"./sea_level_north_atlantic.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data that needs the most cleaning work done is the shark attack data because\n",
    "- it contains columns that are irrelevant to our research or revealed personal information\n",
    "- it contains shark attacks in regions/areas of the world that are not relevant to our scope.\n",
    "- it contains rows for *provoked* shark attacks when we are really trying to research relative to *unprovoked* shark attacks\n",
    "- it is missing categorization of areas of attacks between East and West Coast\n",
    "\n",
    "Thus, pertaining to the shark attack data, we cleaned up our data as follows:\n",
    "1. read in the shark attack csv file\n",
    "2. filtered the dataset to only areas that we of interest (North America)\n",
    "    * looked at all unique values for countries\n",
    "    * defined which of these values to retain\n",
    "    * dropped rows for values in which don't exist in our area of interest\n",
    "3. filtered the dataset to only include rows that had their 'Type' column value as 'unprovoked'\n",
    "4. dropped columns that were either irrelevant or included personal data\n",
    "5. categorized the areas into East and West Coast appropriately"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25847, 24)\n",
      "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
      "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
      "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
      "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
      "       'Unnamed: 23'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# get a feel for the data\n",
    "print(sharks_df.shape)\n",
    "print(sharks_df.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA' 'BAHAMAS' 'AUSTRALIA' 'SOUTH AFRICA' 'ENGLAND' 'JAPAN' 'INDONESIA'\n",
      " 'EGYPT' 'JA MAICA' 'BELIZE' 'MALDIVES' 'FRENCH POLYNESIA' 'THAILAND'\n",
      " 'COLUMBIA' 'NEW ZEALAND' 'MEXICO' 'COSTA RICA' 'New Zealand' 'BRAZIL'\n",
      " 'British Overseas Territory' 'CANADA' 'ECUADOR' 'JORDAN' 'NEW CALEDONIA'\n",
      " 'JAMAICA' 'ST KITTS / NEVIS' 'ST MARTIN' 'SPAIN' 'FIJI' 'SEYCHELLES'\n",
      " 'PAPUA NEW GUINEA' 'REUNION ISLAND' 'ISRAEL' 'CHINA' 'SAMOA' 'IRELAND'\n",
      " 'ITALY' 'COLOMBIA' 'MALAYSIA' 'LIBYA' nan 'CUBA' 'MAURITIUS'\n",
      " 'SOLOMON ISLANDS' 'ST HELENA, British overseas territory' 'COMOROS'\n",
      " 'REUNION' 'UNITED KINGDOM' 'UNITED ARAB EMIRATES' 'PHILIPPINES'\n",
      " 'CAPE VERDE' 'Fiji' 'DOMINICAN REPUBLIC' 'CAYMAN ISLANDS' 'ARUBA'\n",
      " 'MOZAMBIQUE' 'PUERTO RICO' 'ATLANTIC OCEAN' 'GREECE' 'ST. MARTIN'\n",
      " 'FRANCE' 'TRINIDAD & TOBAGO' 'KIRIBATI' 'DIEGO GARCIA' 'TAIWAN'\n",
      " 'PALESTINIAN TERRITORIES' 'GUAM' 'NIGERIA' 'TONGA' 'SCOTLAND' 'CROATIA'\n",
      " 'SAUDI ARABIA' 'CHILE' 'ANTIGUA' 'KENYA' 'RUSSIA' 'TURKS & CAICOS'\n",
      " 'UNITED ARAB EMIRATES (UAE)' 'AZORES' 'SOUTH KOREA' 'MALTA' 'VIETNAM'\n",
      " 'MADAGASCAR' 'PANAMA' 'SOMALIA' 'NEVIS' 'BRITISH VIRGIN ISLANDS' 'NORWAY'\n",
      " 'SENEGAL' 'YEMEN' 'GULF OF ADEN' 'Sierra Leone' 'ST. MAARTIN'\n",
      " 'GRAND CAYMAN' 'Seychelles' 'LIBERIA' 'VANUATU' 'MEXICO ' 'HONDURAS'\n",
      " 'VENEZUELA' 'SRI LANKA' ' TONGA' 'URUGUAY' 'INDIA' 'MICRONESIA'\n",
      " 'CARIBBEAN SEA' 'OKINAWA' 'TANZANIA' 'MARSHALL ISLANDS' 'EGYPT / ISRAEL'\n",
      " 'NORTHERN ARABIAN SEA' 'HONG KONG' 'EL SALVADOR' 'ANGOLA' 'BERMUDA'\n",
      " 'MONTENEGRO' 'IRAN' 'TUNISIA' 'NAMIBIA' 'NORTH ATLANTIC OCEAN' 'PORTUGAL'\n",
      " 'SOUTH CHINA SEA' 'BANGLADESH' 'PALAU' 'WESTERN SAMOA' 'PACIFIC OCEAN '\n",
      " 'BRITISH ISLES' 'GRENADA' 'IRAQ' 'TURKEY' 'SINGAPORE' 'NEW BRITAIN'\n",
      " 'SUDAN' 'JOHNSTON ISLAND' 'SOUTH PACIFIC OCEAN' 'NEW GUINEA' 'RED SEA'\n",
      " 'NORTH PACIFIC OCEAN' 'FEDERATED STATES OF MICRONESIA'\n",
      " 'MID ATLANTIC OCEAN' 'ADMIRALTY ISLANDS' 'BRITISH WEST INDIES'\n",
      " 'SOUTH ATLANTIC OCEAN' 'PERSIAN GULF' 'RED SEA / INDIAN OCEAN'\n",
      " 'PACIFIC OCEAN' 'NORTH SEA' 'NICARAGUA ' 'MALDIVE ISLANDS'\n",
      " 'AMERICAN SAMOA' 'ANDAMAN / NICOBAR ISLANDAS' 'GABON' 'MAYOTTE'\n",
      " 'NORTH ATLANTIC OCEAN ' 'THE BALKANS' 'SUDAN?' 'ARGENTINA' 'MARTINIQUE'\n",
      " 'INDIAN OCEAN' 'GUATEMALA' 'NETHERLANDS ANTILLES'\n",
      " 'NORTHERN MARIANA ISLANDS' 'IRAN / IRAQ' 'JAVA' 'SIERRA LEONE'\n",
      " ' PHILIPPINES' 'NICARAGUA' 'CENTRAL PACIFIC' 'SOLOMON ISLANDS / VANUATU'\n",
      " 'SOUTHWEST PACIFIC OCEAN' 'BAY OF BENGAL' 'MID-PACIFC OCEAN' 'SLOVENIA'\n",
      " 'CURACAO' 'ICELAND' 'ITALY / CROATIA' 'BARBADOS' 'MONACO' 'GUYANA'\n",
      " 'HAITI' 'SAN DOMINGO' 'KUWAIT' 'YEMEN ' 'FALKLAND ISLANDS' 'CRETE'\n",
      " 'CYPRUS' 'EGYPT ' 'WEST INDIES' 'BURMA' 'LEBANON' 'PARAGUAY'\n",
      " 'BRITISH NEW GUINEA' 'CEYLON' 'OCEAN' 'GEORGIA' 'SYRIA' 'TUVALU'\n",
      " 'INDIAN OCEAN?' 'GUINEA' 'ANDAMAN ISLANDS' 'EQUATORIAL GUINEA / CAMEROON'\n",
      " 'COOK ISLANDS' 'TOBAGO' 'PERU' 'AFRICA' 'ALGERIA' 'Coast of AFRICA'\n",
      " 'TASMAN SEA' 'GHANA' 'GREENLAND' 'MEDITERRANEAN SEA' 'SWEDEN' 'ROATAN'\n",
      " 'Between PORTUGAL & INDIA' 'DJIBOUTI' 'BAHREIN' 'KOREA' 'RED SEA?'\n",
      " 'ASIA?' 'CEYLON (SRI LANKA)']\n"
     ]
    }
   ],
   "source": [
    "# look at all unique countries\n",
    "print(sharks_df['Country'].unique())\n",
    "\n",
    "# filter by area, unprovoked attacks, and relevant year frame\n",
    "sharks_df = sharks_df[sharks_df['Country'] == 'USA']\n",
    "sharks_df = sharks_df[sharks_df['Type'] == 'Unprovoked']\n",
    "sharks_df = sharks_df[sharks_df['Year'] >= 1880]\n",
    "\n",
    "# drop irrelevant or ethically exposing columns\n",
    "sharks_df = sharks_df.drop(columns=['Investigator or Source', 'Injury', 'Time', 'pdf','Species ', 'href formula', 'Name', 'Unnamed: 22', 'Unnamed: 23', 'Case Number.1', 'Case Number.2', 'href', 'original order']).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['California' 'Hawaii' 'Louisiana' 'South Carolina' 'Florida' 'New York'\n",
      " 'Noirth Carolina' 'Alabama' 'Texas' 'Maryland' 'North Carolina' 'Georgia'\n",
      " 'Oregon' 'Franklin County, Florida' 'Virgin Islands' 'Maine' 'Bahamas'\n",
      " 'Maui' 'Guam' 'Cayman Islands' 'Rhode Island' 'New Jersey'\n",
      " 'Massachusetts' 'Washington' 'Delaware' 'Palmyra Atoll' 'Puerto Rico'\n",
      " 'Virginia' 'US Virgin Islands' 'South Carolina ' 'Johnston Atoll'\n",
      " 'Connecticut' 'Mississippi' 'Wake Island' ' North Carolina'\n",
      " 'Midway Atoll' 'East coast']\n"
     ]
    }
   ],
   "source": [
    "# categorize 'Area' column values to 'East Coast' or 'West Coast'\n",
    "print(sharks_df['Area'].unique())\n",
    "\n",
    "west_coast = ['California', 'Hawaii', 'Texas', 'Oregon', 'Guam', 'Maui', 'Baja ', 'Guerrero',\n",
    "              'Washington', 'Baja California Sur', 'Palmyra Atoll', 'Johnston Atoll', 'Midway Atoll']\n",
    "\n",
    "east_coast = ['Louisiana', 'South Carolina', 'Florida','New York', 'Noirth Carolina', 'Alabama',\n",
    "              'Maryland', 'North Carolina', 'Georgia', 'Franklin County, Florida', 'Virgin Islands',\n",
    "              'Maine', 'Bahamas', 'Cayman Islands', 'Rhode Island', 'New Jersey', 'Massachusetts', 'Delaware',\n",
    "              'Virginia', 'Puerto Rico', 'US Virgin Islands', 'South Carolina ', 'Connecticut', 'Mississippi',\n",
    "              'Wake Island', ' North Carolina', 'East coast']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def categorize_east_west(str_in):\n",
    "    if str_in in west_coast:\n",
    "        return 'West Coast'\n",
    "    return 'East Coast'\n",
    "\n",
    "sharks_df['West/East Coast'] = sharks_df['Area'].apply(categorize_east_west)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   Case Number         Date    Year        Type Country        Area  \\\n0   2022.10.31  31-Oct-2022  2022.0  Unprovoked     USA  California   \n1   2022.10.25  25 Oct-2022  2022.0  Unprovoked     USA      Hawaii   \n2   2022.10.08  08-Oct-2022  2022.0  Unprovoked     USA   Louisiana   \n3  2022.010.02  02-Oct-2022  2022.0  Unprovoked     USA  California   \n4   2022.09.03  03-Sep-2022  2022.0  Unprovoked     USA      Hawaii   \n\n                      Location                 Activity Sex   Age Fatal (Y/N)  \\\n0   Otter Point, Pacific Grove                  Surfing    M  NaN           N   \n1                        Kauai               Snorkeling    M   51           N   \n2          25 miles off Empire                Shipwreck    M   40           N   \n3            Centerville Beach                  Surfing    M   31           N   \n4  Lower Paia Beach Park, Maui  Swimming  or Snorkeling    F   51           N   \n\n  West/East Coast  \n0      West Coast  \n1      West Coast  \n2      East Coast  \n3      West Coast  \n4      West Coast  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Case Number</th>\n      <th>Date</th>\n      <th>Year</th>\n      <th>Type</th>\n      <th>Country</th>\n      <th>Area</th>\n      <th>Location</th>\n      <th>Activity</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fatal (Y/N)</th>\n      <th>West/East Coast</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022.10.31</td>\n      <td>31-Oct-2022</td>\n      <td>2022.0</td>\n      <td>Unprovoked</td>\n      <td>USA</td>\n      <td>California</td>\n      <td>Otter Point, Pacific Grove</td>\n      <td>Surfing</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>West Coast</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022.10.25</td>\n      <td>25 Oct-2022</td>\n      <td>2022.0</td>\n      <td>Unprovoked</td>\n      <td>USA</td>\n      <td>Hawaii</td>\n      <td>Kauai</td>\n      <td>Snorkeling</td>\n      <td>M</td>\n      <td>51</td>\n      <td>N</td>\n      <td>West Coast</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022.10.08</td>\n      <td>08-Oct-2022</td>\n      <td>2022.0</td>\n      <td>Unprovoked</td>\n      <td>USA</td>\n      <td>Louisiana</td>\n      <td>25 miles off Empire</td>\n      <td>Shipwreck</td>\n      <td>M</td>\n      <td>40</td>\n      <td>N</td>\n      <td>East Coast</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022.010.02</td>\n      <td>02-Oct-2022</td>\n      <td>2022.0</td>\n      <td>Unprovoked</td>\n      <td>USA</td>\n      <td>California</td>\n      <td>Centerville Beach</td>\n      <td>Surfing</td>\n      <td>M</td>\n      <td>31</td>\n      <td>N</td>\n      <td>West Coast</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022.09.03</td>\n      <td>03-Sep-2022</td>\n      <td>2022.0</td>\n      <td>Unprovoked</td>\n      <td>USA</td>\n      <td>Hawaii</td>\n      <td>Lower Paia Beach Park, Maui</td>\n      <td>Swimming  or Snorkeling</td>\n      <td>F</td>\n      <td>51</td>\n      <td>N</td>\n      <td>West Coast</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at our cleaned-up shark data\n",
    "sharks_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the remaining datasets (sea_level & temperature_anomalies), most of the data we already clean so we only made the following changes:\n",
    "1. Removed first 4 rows in the ocean temperature dataset because it stored irrelevant data.\n",
    "2. The intial column names in the ocean temperature dataset did not make sense for the values that are stored, so we changed the column names to appropriate titles (Year, Temperature Anomaly (Celsius))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 2)\n",
      "Index(['Northern Hemisphere Ocean Temperature Anomalies', ' January-December'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "  Northern Hemisphere Ocean Temperature Anomalies  January-December\n0                          Units: Degrees Celsius               NaN\n1                          Base Period: 1901-2000               NaN\n2                                   Missing: -999               NaN\n3                                            Year             Value\n4                                            1880             -0.02",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Northern Hemisphere Ocean Temperature Anomalies</th>\n      <th>January-December</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Units: Degrees Celsius</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Base Period: 1901-2000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Missing: -999</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Year</td>\n      <td>Value</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1880</td>\n      <td>-0.02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a feel for the data\n",
    "print(temp_df.shape)\n",
    "print(temp_df.columns)\n",
    "\n",
    "temp_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   Year Temperature Anomaly (Celsius)\n0  1880                         -0.02\n1  1881                         -0.02\n2  1882                         -0.03\n3  1883                         -0.08\n4  1884                         -0.16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Temperature Anomaly (Celsius)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1880</td>\n      <td>-0.02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1881</td>\n      <td>-0.02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1882</td>\n      <td>-0.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1883</td>\n      <td>-0.08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1884</td>\n      <td>-0.16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to remove unnecessary initial rows (0-4)\n",
    "temp_df = temp_df.loc[4:].reset_index(drop=True)\n",
    "\n",
    "# rename column titles appropriately\n",
    "temp_df = temp_df.rename(columns={'Northern Hemisphere Ocean Temperature Anomalies': 'Year', ' January-December': 'Temperature Anomaly (Celsius)'})\n",
    "\n",
    "temp_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The sea level data we already clean, so we just read the dataset in with no modifications"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "           year  TOPEX/Poseidon  Jason-1  Jason-2  Jason-3\n0     1992.9611           19.62      NaN      NaN      NaN\n1     1992.9865           -8.28      NaN      NaN      NaN\n2     1993.0126          -16.68      NaN      NaN      NaN\n3     1993.0408          -43.48      NaN      NaN      NaN\n4     1993.0659          -61.18      NaN      NaN      NaN\n...         ...             ...      ...      ...      ...\n1370  2022.5020             NaN      NaN      NaN    66.58\n1371  2022.5291             NaN      NaN      NaN    91.58\n1372  2022.5563             NaN      NaN      NaN    99.38\n1373  2022.5835             NaN      NaN      NaN    99.38\n1374  2022.6058             NaN      NaN      NaN   100.88\n\n[1375 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>TOPEX/Poseidon</th>\n      <th>Jason-1</th>\n      <th>Jason-2</th>\n      <th>Jason-3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1992.9611</td>\n      <td>19.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1992.9865</td>\n      <td>-8.28</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1993.0126</td>\n      <td>-16.68</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1993.0408</td>\n      <td>-43.48</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1993.0659</td>\n      <td>-61.18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1370</th>\n      <td>2022.5020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>66.58</td>\n    </tr>\n    <tr>\n      <th>1371</th>\n      <td>2022.5291</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>91.58</td>\n    </tr>\n    <tr>\n      <th>1372</th>\n      <td>2022.5563</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.38</td>\n    </tr>\n    <tr>\n      <th>1373</th>\n      <td>2022.5835</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.38</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>2022.6058</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.88</td>\n    </tr>\n  </tbody>\n</table>\n<p>1375 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sea level data does not need cleaning, so just read in and examine overall structure\n",
    "\n",
    "sl_pacific_df.shape\n",
    "sl_pacific_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "           year  TOPEX/Poseidon  Jason-1  Jason-2  Jason-3\n0     1992.9620           -0.32      NaN      NaN      NaN\n1     1992.9873           -0.62      NaN      NaN      NaN\n2     1993.0129          -16.42      NaN      NaN      NaN\n3     1993.0413           -8.52      NaN      NaN      NaN\n4     1993.0667          -35.72      NaN      NaN      NaN\n...         ...             ...      ...      ...      ...\n1373  2022.5025             NaN      NaN      NaN    69.24\n1374  2022.5295             NaN      NaN      NaN    83.54\n1375  2022.5567             NaN      NaN      NaN    99.44\n1376  2022.5839             NaN      NaN      NaN   114.54\n1377  2022.6057             NaN      NaN      NaN   104.14\n\n[1378 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>TOPEX/Poseidon</th>\n      <th>Jason-1</th>\n      <th>Jason-2</th>\n      <th>Jason-3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1992.9620</td>\n      <td>-0.32</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1992.9873</td>\n      <td>-0.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1993.0129</td>\n      <td>-16.42</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1993.0413</td>\n      <td>-8.52</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1993.0667</td>\n      <td>-35.72</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1373</th>\n      <td>2022.5025</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>69.24</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>2022.5295</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>83.54</td>\n    </tr>\n    <tr>\n      <th>1375</th>\n      <td>2022.5567</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.44</td>\n    </tr>\n    <tr>\n      <th>1376</th>\n      <td>2022.5839</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>114.54</td>\n    </tr>\n    <tr>\n      <th>1377</th>\n      <td>2022.6057</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>104.14</td>\n    </tr>\n  </tbody>\n</table>\n<p>1378 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for northern atlantic region\n",
    "\n",
    "sl_atlantic_df.shape\n",
    "sl_atlantic_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out EDA on your dataset(s); Describe in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
